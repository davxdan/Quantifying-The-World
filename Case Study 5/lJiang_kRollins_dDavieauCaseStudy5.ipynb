{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ To get ml_metrics installed I had to use Anaconda command prompt and run __pip install ml_metrics__.  I am under the impression that we should avoid using pip in an Anaconda environment but I had no choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from ml_metrics import rmse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "# Convert the matrix to pandas\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns = boston.feature_names\n",
    "bos['MEDV'] = boston.target\n",
    "#bos.head()\n",
    "bos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof = ProfileReport(bos)\n",
    "# ProfileReport(bos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__\n",
    "Use sklearn.datasets to get the Boston Housing dataset.  Fit a linear regressor to the data as a baseline.  There is no need to do Cross-Validation.  We will simply be exploring the change in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = bos.sample(frac=0.7, random_state=100)\n",
    "test_set = bos[~bos.isin(train_set)].dropna()\n",
    "# Get the training and testing row indices for later use\n",
    "train_index = train_set.index.values.astype(int)\n",
    "test_index = test_set.index.values.astype(int)\n",
    "\n",
    "# Converting the training and testing datasets back to matrix-formats\n",
    "X_train = train_set.iloc[:, :-1].values # returns the data; excluding the target\n",
    "Y_train = train_set.iloc[:, -1].values # returns the target-only\n",
    "X_test = test_set.iloc[:, :-1].values # \"\"\n",
    "Y_test = test_set.iloc[:, -1].values # \"\"\n",
    "\n",
    "# Fit a linear regression to the training data\n",
    "reg = LinearRegression(normalize=True).fit(X_train, Y_train)\n",
    "\n",
    "#Predict\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "#Get measures\n",
    "orig_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "orig_mse = mean_squared_error(Y_test,Y_pred)\n",
    "orig_rmse_val = rmse(Y_test,Y_pred)\n",
    "orig_r2 = r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_frame = pd.DataFrame({'data':'original',\n",
    "                   'imputation':'none',\n",
    "                   'mae': orig_mae, \n",
    "                   'mse': orig_mse, \n",
    "                   'rmse':orig_rmse_val, \n",
    "                   'R2':orig_r2,\n",
    "                   'mae_diff':np.nan,\n",
    "                   'mse_diff':np.nan,\n",
    "                   'rmse_diff':np.nan,\n",
    "                   'R2_diff':np.nan}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1:__ What is the loss and what are the goodness of fit parameters?  This will be our baseline for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.70494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data imputation       mae        mse      rmse       R2  mae_diff  \\\n",
       "0  original       none  3.604571  24.098505  4.909023  0.70494       NaN   \n",
       "\n",
       "   mse_diff  rmse_diff  R2_diff  \n",
       "0       NaN        NaN      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ (repeat for each percentage value below)\n",
    "Select 1%, 5% 10%, 20%, 33%, and 50% of your data in a single column [hold that column selection constant throughout all iterations] (Completely at random), replace the original value with a NaN (i.e., “not a number” – ex., np.nan) and then perform an imputation for the missing values.   \n",
    "\n",
    "__Question 2:__ In each case [1%, 5%, 10%, 20%, 33%, 50%] perform a fit with the imputed data and compare the loss and goodness of fit to your baseline.  [Note: you should have (6) models to compare against your baseline at this point.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definedsample(data, fraction, featurename, resultframe):\n",
    "    in_sample = data.sample(frac=fraction, random_state=99)\n",
    "    out_sample = data[~data.isin(in_sample)].dropna()\n",
    "    in_sample[featurename] = np.nan\n",
    "    in_sample[featurename] = in_sample[featurename].fillna(out_sample[featurename].mean())\n",
    "    sampleddata = pd.concat([in_sample, out_sample])\n",
    "    sampleddata = sampleddata.sort_index()\n",
    "    train_set = sampleddata.iloc[train_index]\n",
    "    test_set = sampleddata.iloc[test_index]\n",
    "    X_train = train_set.iloc[:, :-1].values\n",
    "    Y_train = train_set.iloc[:, -1].values\n",
    "    X_test = test_set.iloc[:, :-1].values\n",
    "    Y_test = test_set.iloc[:, -1].values\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "    Y_pred = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test,Y_pred)\n",
    "    mse = mean_squared_error(Y_test,Y_pred)\n",
    "    rmse_val = rmse(Y_test,Y_pred)\n",
    "    r2 = r2_score(Y_test,Y_pred)\n",
    "    print(in_sample.iloc)\n",
    "    temp_frame = pd.DataFrame({'data': str(fraction)+'% missing completely at random: imputed using mean',\n",
    "                   'imputation':'Mean',\n",
    "                   'mae': mae, \n",
    "                   'mse': mse, \n",
    "                   'rmse':rmse_val,\n",
    "                   'R2':r2,\n",
    "                   'mae_diff':mae-orig_mae,\n",
    "                   'mse_diff':mse-orig_mse,\n",
    "                   'rmse_diff':rmse_val-orig_rmse_val,\n",
    "                   'R2_diff':r2-orig_r2\n",
    "                   }, index=[0])\n",
    "    resultframe = pd.concat([resultframe, temp_frame])\n",
    "    return resultframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._iLocIndexer object at 0x000001F9DAB9F4F8>\n",
      "<pandas.core.indexing._iLocIndexer object at 0x000001F9DAB9FC28>\n",
      "<pandas.core.indexing._iLocIndexer object at 0x000001F9DAB9F138>\n",
      "<pandas.core.indexing._iLocIndexer object at 0x000001F9DAB9F368>\n",
      "<pandas.core.indexing._iLocIndexer object at 0x000001F9DAB9F228>\n"
     ]
    }
   ],
   "source": [
    "res_frame = definedsample(bos,.01,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.05,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.10,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.20,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.5,'DIS',res_frame)\n",
    "#Fix the math for the percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.704940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.638791</td>\n",
       "      <td>24.316646</td>\n",
       "      <td>4.931191</td>\n",
       "      <td>0.702269</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.218141</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>-0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.553488</td>\n",
       "      <td>23.977540</td>\n",
       "      <td>4.896687</td>\n",
       "      <td>0.706421</td>\n",
       "      <td>-0.051083</td>\n",
       "      <td>-0.120964</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.547616</td>\n",
       "      <td>24.027511</td>\n",
       "      <td>4.901786</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-0.070994</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.641010</td>\n",
       "      <td>25.303311</td>\n",
       "      <td>5.030240</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>1.204806</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-0.014752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.624329</td>\n",
       "      <td>25.662844</td>\n",
       "      <td>5.065851</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>1.564339</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>-0.019154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data imputation       mae  \\\n",
       "0                                           original       none  3.604571   \n",
       "0  0.01% missing completely at random: imputed us...       Mean  3.638791   \n",
       "0  0.05% missing completely at random: imputed us...       Mean  3.553488   \n",
       "0  0.1% missing completely at random: imputed usi...       Mean  3.547616   \n",
       "0  0.2% missing completely at random: imputed usi...       Mean  3.641010   \n",
       "0  0.5% missing completely at random: imputed usi...       Mean  3.624329   \n",
       "\n",
       "         mse      rmse        R2  mae_diff  mse_diff  rmse_diff   R2_diff  \n",
       "0  24.098505  4.909023  0.704940       NaN       NaN        NaN       NaN  \n",
       "0  24.316646  4.931191  0.702269  0.034219  0.218141   0.022168 -0.002671  \n",
       "0  23.977540  4.896687  0.706421 -0.051083 -0.120964  -0.012336  0.001481  \n",
       "0  24.027511  4.901786  0.705809 -0.056955 -0.070994  -0.007236  0.000869  \n",
       "0  25.303311  5.030240  0.690188  0.036439  1.204806   0.121217 -0.014752  \n",
       "0  25.662844  5.065851  0.685786  0.019757  1.564339   0.156828 -0.019154  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Take two columns and create data “Missing at Random” when controlled for a third variable (i.e., if Variable Z is > 30, then Variables X, Y are randomly missing).  Use your preferred imputation method to fill in 10%, 20% and 30% of your missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ Function below takes in multiple feature names of our choice. However the Z criterion from instructions I just hard coded for __INDUS < 7__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definedsampleXYZ(data, fraction, missingfeaturenames, resultframe):\n",
    "    in_sample = data.sample(frac=fraction, random_state=99)\n",
    "    out_sample = data[~data.isin(in_sample)].dropna()\n",
    "    \n",
    "    for x in missingfeaturenames:\n",
    "        in_sample.loc[in_sample['INDUS'] < 7, x] = np.nan\n",
    "        in_sample[x] = in_sample[x].fillna(out_sample[x].mean())\n",
    "    \n",
    "    sampleddata = pd.concat([in_sample, out_sample])\n",
    "    sampleddata = sampleddata.sort_index()\n",
    "        \n",
    "    train_set = sampleddata.iloc[train_index]\n",
    "    test_set = sampleddata.iloc[test_index]\n",
    "    X_train = train_set.iloc[:, :-1].values\n",
    "    Y_train = train_set.iloc[:, -1].values\n",
    "    X_test = test_set.iloc[:, :-1].values\n",
    "    Y_test = test_set.iloc[:, -1].values\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "    Y_pred = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test,Y_pred)\n",
    "    mse = mean_squared_error(Y_test,Y_pred)\n",
    "    rmse_val = rmse(Y_test,Y_pred)\n",
    "    r2 = r2_score(Y_test,Y_pred)\n",
    "    \n",
    "    temp_frame = pd.DataFrame({'data': str(fraction)+'% missing at random where INDUS > 7: imputed using mean',\n",
    "                   'imputation':'Mean',\n",
    "                   'mae': mae, \n",
    "                   'mse': mse, \n",
    "                   'rmse':rmse_val,\n",
    "                   'R2':r2,\n",
    "                   'mae_diff':mae-orig_mae,\n",
    "                   'mse_diff':mse-orig_mse,\n",
    "                   'rmse_diff':rmse_val-orig_rmse_val,\n",
    "                   'R2_diff':r2-orig_r2\n",
    "                   }, index=[0])\n",
    "    resultframe = pd.concat([resultframe, temp_frame])\n",
    "    #print(in_sample.describe())\n",
    "    return resultframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missingXandY = ['DIS', 'NOX']\n",
    "\n",
    "res_frame = definedsampleXYZ(bos,.1,missingXandY,res_frame)\n",
    "res_frame = definedsampleXYZ(bos,.2,missingXandY,res_frame)\n",
    "res_frame = definedsampleXYZ(bos,.3,missingXandY,res_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__ In each case [10%, 20%, 30%] perform a fit with the imputed data and compare the loss and goodness of fit to your baseline.  [Note: you should have (9) models to compare against your baseline at this point.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.704940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.638791</td>\n",
       "      <td>24.316646</td>\n",
       "      <td>4.931191</td>\n",
       "      <td>0.702269</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.218141</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>-0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.553488</td>\n",
       "      <td>23.977540</td>\n",
       "      <td>4.896687</td>\n",
       "      <td>0.706421</td>\n",
       "      <td>-0.051083</td>\n",
       "      <td>-0.120964</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.547616</td>\n",
       "      <td>24.027511</td>\n",
       "      <td>4.901786</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-0.070994</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.641010</td>\n",
       "      <td>25.303311</td>\n",
       "      <td>5.030240</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>1.204806</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-0.014752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.624329</td>\n",
       "      <td>25.662844</td>\n",
       "      <td>5.065851</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>1.564339</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>-0.019154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.630117</td>\n",
       "      <td>24.335170</td>\n",
       "      <td>4.933069</td>\n",
       "      <td>0.702042</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.236665</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>-0.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.611678</td>\n",
       "      <td>24.237506</td>\n",
       "      <td>4.923160</td>\n",
       "      <td>0.703238</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.139001</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>-0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.619581</td>\n",
       "      <td>24.641156</td>\n",
       "      <td>4.963986</td>\n",
       "      <td>0.698296</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.542652</td>\n",
       "      <td>0.054963</td>\n",
       "      <td>-0.006644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data imputation       mae  \\\n",
       "0                                           original       none  3.604571   \n",
       "0  0.01% missing completely at random: imputed us...       Mean  3.638791   \n",
       "0  0.05% missing completely at random: imputed us...       Mean  3.553488   \n",
       "0  0.1% missing completely at random: imputed usi...       Mean  3.547616   \n",
       "0  0.2% missing completely at random: imputed usi...       Mean  3.641010   \n",
       "0  0.5% missing completely at random: imputed usi...       Mean  3.624329   \n",
       "0  0.1% missing at random where INDUS > 7: impute...       Mean  3.630117   \n",
       "0  0.2% missing at random where INDUS > 7: impute...       Mean  3.611678   \n",
       "0  0.3% missing at random where INDUS > 7: impute...       Mean  3.619581   \n",
       "\n",
       "         mse      rmse        R2  mae_diff  mse_diff  rmse_diff   R2_diff  \n",
       "0  24.098505  4.909023  0.704940       NaN       NaN        NaN       NaN  \n",
       "0  24.316646  4.931191  0.702269  0.034219  0.218141   0.022168 -0.002671  \n",
       "0  23.977540  4.896687  0.706421 -0.051083 -0.120964  -0.012336  0.001481  \n",
       "0  24.027511  4.901786  0.705809 -0.056955 -0.070994  -0.007236  0.000869  \n",
       "0  25.303311  5.030240  0.690188  0.036439  1.204806   0.121217 -0.014752  \n",
       "0  25.662844  5.065851  0.685786  0.019757  1.564339   0.156828 -0.019154  \n",
       "0  24.335170  4.933069  0.702042  0.025546  0.236665   0.024046 -0.002898  \n",
       "0  24.237506  4.923160  0.703238  0.007107  0.139001   0.014137 -0.001702  \n",
       "0  24.641156  4.963986  0.698296  0.015010  0.542652   0.054963 -0.006644  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__  Create a “Missing Not at Random” pattern in which 25% of the data is missing for a single column.\n",
    "(__concensus:__ remove a quartile)\n",
    "\n",
    "__Question 4:__ Perform a fit with the imputed data [25%] and compare the loss and goodness of fit to your baseline.  [Note: you should have (10) models to compare against your baseline at this point.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ We use a function to remove the 1st quartile (anything less than 2.100175) from __only the DIS__ feature. This time hard-coding for DIS rather than INDUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    506.000000\n",
       "mean       3.795043\n",
       "std        2.105710\n",
       "min        1.129600\n",
       "25%        2.100175\n",
       "50%        3.207450\n",
       "75%        5.188425\n",
       "max       12.126500\n",
       "Name: DIS, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos.DIS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#temp.DIS.loc[temp.DIS < 2.100175] = np.nan #<<This works dont fuck it up\n",
    "#temp['DIS'].loc[temp['DIS'] < 2.100175] = np.nan <<This works too.. dont fuck it up\n",
    "#temp.DIS.describe()\n",
    "\n",
    "#temp=bos\n",
    "# temp.DIS.loc[temp.DIS < 2.100175] = np.nan\n",
    "# tempmean= temp.DIS.mean()\n",
    "# temp.DIS = temp.DIS.fillna(tempmean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we opt to remove the lower quartile we have to handle \n",
    "#getting the mean differently. We first drop the quartile and then take the mean which inherently means our model will be terrible depenting on variable importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definedsample25(data, featurename, resultframe):\n",
    "    data[featurename].loc[data[featurename] < 2.100175] = np.nan\n",
    "    data[featurename] = data[featurename].fillna(data[featurename].mean())\n",
    "    sampleddata = data\n",
    "    sampleddata = sampleddata.sort_index()\n",
    "    train_set = sampleddata.iloc[train_index]\n",
    "    test_set = sampleddata.iloc[test_index]\n",
    "    X_train = train_set.iloc[:, :-1].values\n",
    "    Y_train = train_set.iloc[:, -1].values\n",
    "    X_test = test_set.iloc[:, :-1].values\n",
    "    Y_test = test_set.iloc[:, -1].values\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "    Y_pred = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test,Y_pred)\n",
    "    mse = mean_squared_error(Y_test,Y_pred)\n",
    "    rmse_val = rmse(Y_test,Y_pred)\n",
    "    r2 = r2_score(Y_test,Y_pred)\n",
    "   \n",
    "    temp_frame = pd.DataFrame({'data': '1st quartile missing not at random: imputed using mean',\n",
    "                   'imputation':'Mean',\n",
    "                   'mae': mae, \n",
    "                   'mse': mse, \n",
    "                   'rmse':rmse_val,\n",
    "                   'R2':r2,\n",
    "                   'mae_diff':mae-orig_mae,\n",
    "                   'mse_diff':mse-orig_mse,\n",
    "                   'rmse_diff':rmse_val-orig_rmse_val,\n",
    "                   'R2_diff':r2-orig_r2\n",
    "                   }, index=[0])\n",
    "    resultframe = pd.concat([resultframe, temp_frame])\n",
    "    return resultframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingXandY = 'DIS'\n",
    "res_frame = definedsample25(bos,missingXandY,res_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.704940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.638791</td>\n",
       "      <td>24.316646</td>\n",
       "      <td>4.931191</td>\n",
       "      <td>0.702269</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.218141</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>-0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05% missing completely at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.553488</td>\n",
       "      <td>23.977540</td>\n",
       "      <td>4.896687</td>\n",
       "      <td>0.706421</td>\n",
       "      <td>-0.051083</td>\n",
       "      <td>-0.120964</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.547616</td>\n",
       "      <td>24.027511</td>\n",
       "      <td>4.901786</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-0.070994</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.641010</td>\n",
       "      <td>25.303311</td>\n",
       "      <td>5.030240</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>1.204806</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-0.014752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5% missing completely at random: imputed usi...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.624329</td>\n",
       "      <td>25.662844</td>\n",
       "      <td>5.065851</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>1.564339</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>-0.019154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.630117</td>\n",
       "      <td>24.335170</td>\n",
       "      <td>4.933069</td>\n",
       "      <td>0.702042</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.236665</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>-0.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.611678</td>\n",
       "      <td>24.237506</td>\n",
       "      <td>4.923160</td>\n",
       "      <td>0.703238</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.139001</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>-0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3% missing at random where INDUS &gt; 7: impute...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.619581</td>\n",
       "      <td>24.641156</td>\n",
       "      <td>4.963986</td>\n",
       "      <td>0.698296</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.542652</td>\n",
       "      <td>0.054963</td>\n",
       "      <td>-0.006644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st quartile missing not at random: imputed us...</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.667832</td>\n",
       "      <td>25.719009</td>\n",
       "      <td>5.071391</td>\n",
       "      <td>0.685099</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>1.620504</td>\n",
       "      <td>0.162368</td>\n",
       "      <td>-0.019841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data imputation       mae  \\\n",
       "0                                           original       none  3.604571   \n",
       "0  0.01% missing completely at random: imputed us...       Mean  3.638791   \n",
       "0  0.05% missing completely at random: imputed us...       Mean  3.553488   \n",
       "0  0.1% missing completely at random: imputed usi...       Mean  3.547616   \n",
       "0  0.2% missing completely at random: imputed usi...       Mean  3.641010   \n",
       "0  0.5% missing completely at random: imputed usi...       Mean  3.624329   \n",
       "0  0.1% missing at random where INDUS > 7: impute...       Mean  3.630117   \n",
       "0  0.2% missing at random where INDUS > 7: impute...       Mean  3.611678   \n",
       "0  0.3% missing at random where INDUS > 7: impute...       Mean  3.619581   \n",
       "0  1st quartile missing not at random: imputed us...       Mean  3.667832   \n",
       "\n",
       "         mse      rmse        R2  mae_diff  mse_diff  rmse_diff   R2_diff  \n",
       "0  24.098505  4.909023  0.704940       NaN       NaN        NaN       NaN  \n",
       "0  24.316646  4.931191  0.702269  0.034219  0.218141   0.022168 -0.002671  \n",
       "0  23.977540  4.896687  0.706421 -0.051083 -0.120964  -0.012336  0.001481  \n",
       "0  24.027511  4.901786  0.705809 -0.056955 -0.070994  -0.007236  0.000869  \n",
       "0  25.303311  5.030240  0.690188  0.036439  1.204806   0.121217 -0.014752  \n",
       "0  25.662844  5.065851  0.685786  0.019757  1.564339   0.156828 -0.019154  \n",
       "0  24.335170  4.933069  0.702042  0.025546  0.236665   0.024046 -0.002898  \n",
       "0  24.237506  4.923160  0.703238  0.007107  0.139001   0.014137 -0.001702  \n",
       "0  24.641156  4.963986  0.698296  0.015010  0.542652   0.054963 -0.006644  \n",
       "0  25.719009  5.071391  0.685099  0.063261  1.620504   0.162368 -0.019841  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Describe your imputation approach and summarize your findings.  What impact did the missing data have on your baseline model’s performance? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
