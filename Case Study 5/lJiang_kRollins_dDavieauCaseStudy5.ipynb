{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ To get ml_metrics installed I had to use Anaconda command prompt and run __pip install ml_metrics__.  I am under the impression that we should avoid using pip in an Anaconda environment but I had no choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from ml_metrics import rmse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "# Convert the matrix to pandas\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns = boston.feature_names\n",
    "bos['MEDV'] = boston.target\n",
    "#bos.head()\n",
    "#bos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__\n",
    "Use sklearn.datasets to get the Boston Housing dataset.  Fit a linear regressor to the data as a baseline.  There is no need to do Cross-Validation.  We will simply be exploring the change in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = bos.sample(frac=0.7, random_state=100)\n",
    "test_set = bos[~bos.isin(train_set)].dropna()\n",
    "# Get the training and testing row indices for later use\n",
    "train_index = train_set.index.values.astype(int)\n",
    "test_index = test_set.index.values.astype(int)\n",
    "\n",
    "# Converting the training and testing datasets back to matrix-formats\n",
    "X_train = train_set.iloc[:, :-1].values # returns the data; excluding the target\n",
    "Y_train = train_set.iloc[:, -1].values # returns the target-only\n",
    "X_test = test_set.iloc[:, :-1].values # \"\"\n",
    "Y_test = test_set.iloc[:, -1].values # \"\"\n",
    "\n",
    "# Fit a linear regression to the training data\n",
    "reg = LinearRegression(normalize=True).fit(X_train, Y_train)\n",
    "\n",
    "#Predict\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "#Get measures\n",
    "orig_mae = mean_absolute_error(Y_test,Y_pred)\n",
    "orig_mse = mean_squared_error(Y_test,Y_pred)\n",
    "orig_rmse_val = rmse(Y_test,Y_pred)\n",
    "orig_r2 = r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_frame = pd.DataFrame({'data':'original',\n",
    "                   'imputation':'none',\n",
    "                   'mae': orig_mae, \n",
    "                   'mse': orig_mse, \n",
    "                   'rmse':orig_rmse_val, \n",
    "                   'R2':orig_r2,\n",
    "                   'mae_diff':np.nan,\n",
    "                   'mse_diff':np.nan,\n",
    "                   'rmse_diff':np.nan,\n",
    "                   'R2_diff':np.nan}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1:__ What is the loss and what are the goodness of fit parameters?  This will be our baseline for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.70494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data imputation       mae        mse      rmse       R2  mae_diff  \\\n",
       "0  original       none  3.604571  24.098505  4.909023  0.70494       NaN   \n",
       "\n",
       "   mse_diff  rmse_diff  R2_diff  \n",
       "0       NaN        NaN      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ (repeat for each percentage value below)\n",
    "Select 1%, 5% 10%, 20%, 33%, and 50% of your data in a single column [hold that column selection constant throughout all iterations] (Completely at random), replace the original value with a NaN (i.e., “not a number” – ex., np.nan) and then perform an imputation for the missing values.   \n",
    "\n",
    "__Question 2:__ In each case [1%, 5%, 10%, 20%, 33%, 50%] perform a fit with the imputed data and compare the loss and goodness of fit to your baseline.  [Note: you should have (6) models to compare against your baseline at this point.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definedsample(data, fraction, featurename, resultframe):\n",
    "    in_sample = data.sample(frac=fraction, random_state=99)\n",
    "    out_sample = data[~data.isin(in_sample)].dropna()\n",
    "    in_sample[featurename] = np.nan\n",
    "    in_sample[featurename] = in_sample[featurename].fillna(out_sample[featurename].mean())\n",
    "    sampleddata = pd.concat([in_sample, out_sample])\n",
    "    sampleddata = sampleddata.sort_index()\n",
    "    train_set = sampleddata.iloc[train_index]\n",
    "    test_set = sampleddata.iloc[test_index]\n",
    "    X_train = train_set.iloc[:, :-1].values\n",
    "    Y_train = train_set.iloc[:, -1].values\n",
    "    X_test = test_set.iloc[:, :-1].values\n",
    "    Y_test = test_set.iloc[:, -1].values\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "    Y_pred = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test,Y_pred)\n",
    "    mse = mean_squared_error(Y_test,Y_pred)\n",
    "    rmse_val = rmse(Y_test,Y_pred)\n",
    "    r2 = r2_score(Y_test,Y_pred)\n",
    "    \n",
    "    temp_frame = pd.DataFrame({'data': str(fraction)+'% imputed',\n",
    "                   'imputation':'Mean',\n",
    "                   'mae': mae, \n",
    "                   'mse': mse, \n",
    "                   'rmse':rmse_val,\n",
    "                   'R2':r2,\n",
    "                   'mae_diff':mae-orig_mae,\n",
    "                   'mse_diff':mse-orig_mse,\n",
    "                   'rmse_diff':rmse_val-orig_rmse_val,\n",
    "                   'R2_diff':r2-orig_r2\n",
    "                   }, index=[0])\n",
    "    resultframe = pd.concat([resultframe, temp_frame])\n",
    "    return resultframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_frame = definedsample(bos,.01,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.05,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.10,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.20,'DIS',res_frame)\n",
    "res_frame = definedsample(bos,.5,'DIS',res_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>imputation</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>R2</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>rmse_diff</th>\n",
       "      <th>R2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>none</td>\n",
       "      <td>3.604571</td>\n",
       "      <td>24.098505</td>\n",
       "      <td>4.909023</td>\n",
       "      <td>0.704940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01% imputed</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.638791</td>\n",
       "      <td>24.316646</td>\n",
       "      <td>4.931191</td>\n",
       "      <td>0.702269</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.218141</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>-0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05% imputed</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.553488</td>\n",
       "      <td>23.977540</td>\n",
       "      <td>4.896687</td>\n",
       "      <td>0.706421</td>\n",
       "      <td>-0.051083</td>\n",
       "      <td>-0.120964</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1% imputed</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.547616</td>\n",
       "      <td>24.027511</td>\n",
       "      <td>4.901786</td>\n",
       "      <td>0.705809</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-0.070994</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2% imputed</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.641010</td>\n",
       "      <td>25.303311</td>\n",
       "      <td>5.030240</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>1.204806</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-0.014752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5% imputed</td>\n",
       "      <td>Mean</td>\n",
       "      <td>3.624329</td>\n",
       "      <td>25.662844</td>\n",
       "      <td>5.065851</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>1.564339</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>-0.019154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            data imputation       mae        mse      rmse        R2  \\\n",
       "0       original       none  3.604571  24.098505  4.909023  0.704940   \n",
       "0  0.01% imputed       Mean  3.638791  24.316646  4.931191  0.702269   \n",
       "0  0.05% imputed       Mean  3.553488  23.977540  4.896687  0.706421   \n",
       "0   0.1% imputed       Mean  3.547616  24.027511  4.901786  0.705809   \n",
       "0   0.2% imputed       Mean  3.641010  25.303311  5.030240  0.690188   \n",
       "0   0.5% imputed       Mean  3.624329  25.662844  5.065851  0.685786   \n",
       "\n",
       "   mae_diff  mse_diff  rmse_diff   R2_diff  \n",
       "0       NaN       NaN        NaN       NaN  \n",
       "0  0.034219  0.218141   0.022168 -0.002671  \n",
       "0 -0.051083 -0.120964  -0.012336  0.001481  \n",
       "0 -0.056955 -0.070994  -0.007236  0.000869  \n",
       "0  0.036439  1.204806   0.121217 -0.014752  \n",
       "0  0.019757  1.564339   0.156828 -0.019154  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampledefinitions = [.01, .05]\n",
    "# for sampledefinition in sampledefinitions:\n",
    "#     definedsample(bos,sampledefinitions,'DIS',res_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Take two columns and create data “Missing at Random” when controlled for a third variable (i.e., if Variable Z is > 30, then Variables X, Y are randomly missing).  Use your preferred imputation method to fill in 10%, 20% and 30% of your missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If INDUS > 9.6 then CHAS,NOX may be missing\n",
    "# in_sample1['DIS'] = in_sample1['DIS'].fillna(out_sample1['DIS'].mean())\n",
    "# imputed_data1 = pd.concat([in_sample1, out_sample1])\n",
    "# imputed_data1 = imputed_data1.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__ In each case [10%, 20%, 30%] perform a fit with the imputed data and compare the loss and goodness of fit to your baseline.  [Note: you should have (9) models to compare against your baseline at this point.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__  Create a “Missing Not at Random” pattern in which 25% of the data is missing for a single column.\n",
    "\n",
    "__Question 4:__ Perform a fit with the imputed data [25%] and compare the loss and goodness of fit to your baseline.  [Note: you should have (10) models to compare against your baseline at this point.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Describe your imputation approach and summarize your findings.  What impact did the missing data have on your baseline model’s performance? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
