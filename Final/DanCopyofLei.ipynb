{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt \n",
    "# #%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports required for analysis are below\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import ipywidgets\n",
    "from ipywidgets import widgets as wd\n",
    "import sklearn\n",
    "# from sklearn import svm\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics as metrics\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import Image\n",
    "# Functions for ROC Graphs\n",
    "#https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "#probs is the result of a model.predict_proba(x_test) call\n",
    "\n",
    "#This function plots an ROC curve\n",
    "def rocCurvePlot(probs, y_test1):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test1, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "# A function to find the optimal cutoff point from ROC curve\n",
    "\n",
    "#https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\"Parameters:\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "    ----------\n",
    "    Return: list type, with optimal cutoff value\n",
    "    \"\"\"\n",
    "    predicted = predicted[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = 'C:/Users/N1110/Desktop/QTW/QTW_Final/'\n",
    "directory = 'C:/Users/danie/Documents/GitHub/Quantifying-The-World/Final'\n",
    "df_raw = pd.read_csv('final_project.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "df_raw['x32'] = df_raw['x32'].str.replace('%', '')\n",
    "df_raw['x32'] = df_raw['x32'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['x37'] = df_raw['x37'].str.replace('$', '')\n",
    "df_raw['x37'] = df_raw['x37'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x34, x33, x10, x23 have 3% missing values, others have below 2%. \n",
    "# we should still have enough data after drop a small percentage of NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.dropna(inplace = True)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x29 only keep 3 characters\n",
    "df_raw['x29'].replace(to_replace='January', value='Jan',inplace=True)\n",
    "df_raw['x29'].replace(to_replace='sept.', value='Sep',inplace=True)\n",
    "df_raw['x29'].replace(to_replace='Dev', value='Dec',inplace=True)\n",
    "df_raw['x29'].replace(to_replace='July', value='Jul',inplace=True)\n",
    "# x32 change to float\n",
    "if(df_raw['x32'].dtypes!='float64'):\n",
    "    df_raw['x32'] =df_raw['x32'].str[:-1].astype(float)\n",
    "# x37 change to float\n",
    "if(df_raw['x37'].dtypes!='float64'):\n",
    "    df_raw['x37'] = df_raw['x37'].str.replace('$', '')\n",
    "    df_raw['x37'] =df_raw['x37'].str[:-1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all obj attributes\n",
    "for col in list(df_raw.select_dtypes(include=['object']).columns):\n",
    "    print(col)\n",
    "    print('------------------------------------------------')\n",
    "    print(df_raw[col].value_counts().sort_values(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate remaining categorical variables\n",
    "begColumnCt = len(df_raw.columns)\n",
    "sD_nominal = df_raw.loc[:, (df_raw.dtypes == object)]\n",
    "\n",
    "#one hot encode categorical variables\n",
    "df_raw = pd.get_dummies(data=df_raw, \n",
    "                       columns=sD_nominal.columns, drop_first=True)\n",
    "\n",
    "#Determine change in column count\n",
    "endColumnCt = len(df_raw.columns)\n",
    "columnsAdded = endColumnCt - begColumnCt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x29_Jun</th>\n",
       "      <th>x29_Mar</th>\n",
       "      <th>x29_May</th>\n",
       "      <th>x29_Nov</th>\n",
       "      <th>x29_Oct</th>\n",
       "      <th>x29_Sep</th>\n",
       "      <th>x30_monday</th>\n",
       "      <th>x30_thurday</th>\n",
       "      <th>x30_tuesday</th>\n",
       "      <th>x30_wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39909</td>\n",
       "      <td>-0.200526</td>\n",
       "      <td>-1.498802</td>\n",
       "      <td>12.502326</td>\n",
       "      <td>-0.086056</td>\n",
       "      <td>2.648814</td>\n",
       "      <td>5.918173</td>\n",
       "      <td>18.177443</td>\n",
       "      <td>-27.667335</td>\n",
       "      <td>14.412525</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122788</td>\n",
       "      <td>-0.025395</td>\n",
       "      <td>4.405048</td>\n",
       "      <td>16.630177</td>\n",
       "      <td>-15.360624</td>\n",
       "      <td>1.049496</td>\n",
       "      <td>-2.587212</td>\n",
       "      <td>24.179028</td>\n",
       "      <td>9.579218</td>\n",
       "      <td>-5.079642</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132992</td>\n",
       "      <td>-0.800132</td>\n",
       "      <td>-2.275084</td>\n",
       "      <td>12.319186</td>\n",
       "      <td>0.368629</td>\n",
       "      <td>-1.998036</td>\n",
       "      <td>3.005167</td>\n",
       "      <td>17.911171</td>\n",
       "      <td>4.069285</td>\n",
       "      <td>-3.997345</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73551</td>\n",
       "      <td>0.461256</td>\n",
       "      <td>-2.348442</td>\n",
       "      <td>-25.594506</td>\n",
       "      <td>8.090648</td>\n",
       "      <td>-0.599051</td>\n",
       "      <td>24.120313</td>\n",
       "      <td>-37.212488</td>\n",
       "      <td>16.707442</td>\n",
       "      <td>2.629158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148086</td>\n",
       "      <td>-0.418037</td>\n",
       "      <td>2.361275</td>\n",
       "      <td>11.605771</td>\n",
       "      <td>-3.929155</td>\n",
       "      <td>-6.374405</td>\n",
       "      <td>-1.792881</td>\n",
       "      <td>16.873919</td>\n",
       "      <td>-29.730196</td>\n",
       "      <td>-14.898756</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        x0        x1         x2         x3        x4         x5  \\\n",
       "0       39909 -0.200526 -1.498802  12.502326  -0.086056  2.648814   5.918173   \n",
       "1      122788 -0.025395  4.405048  16.630177 -15.360624  1.049496  -2.587212   \n",
       "2      132992 -0.800132 -2.275084  12.319186   0.368629 -1.998036   3.005167   \n",
       "3       73551  0.461256 -2.348442 -25.594506   8.090648 -0.599051  24.120313   \n",
       "4      148086 -0.418037  2.361275  11.605771  -3.929155 -6.374405  -1.792881   \n",
       "\n",
       "          x6         x7         x8  ...  x29_Jun  x29_Mar  x29_May  x29_Nov  \\\n",
       "0  18.177443 -27.667335  14.412525  ...        1        0        0        0   \n",
       "1  24.179028   9.579218  -5.079642  ...        1        0        0        0   \n",
       "2  17.911171   4.069285  -3.997345  ...        0        0        0        0   \n",
       "3 -37.212488  16.707442   2.629158  ...        0        0        0        0   \n",
       "4  16.873919 -29.730196 -14.898756  ...        0        0        0        0   \n",
       "\n",
       "   x29_Oct  x29_Sep  x30_monday  x30_thurday  x30_tuesday  x30_wednesday  \n",
       "0        0        0           0            0            0              1  \n",
       "1        0        0           0            0            0              1  \n",
       "2        1        0           0            1            0              0  \n",
       "3        0        0           0            0            0              1  \n",
       "4        0        0           0            0            0              1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed = pd.read_csv(\"df_imputedUpdated2.csv\")  #start with window\n",
    "df_imputed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31678, 66)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'y' in df_imputed:\n",
    "    y = df_imputed['y'].values # get the labels we want\n",
    "    del df_imputed['y'] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and Testing Split\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    # we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# #XGBOOST parameters 1\n",
    "# MAX_ROUNDS = 1000\n",
    "# EARLY_STOP = 50\n",
    "# OPT_ROUNDS = 1000\n",
    "# VERBOSE_EVAL = 50\n",
    "# RANDOM_STATE = 2000\n",
    "\n",
    "# #XGBOOST transform data into DMatrix format for modeling\n",
    "# dtrain = xgb.DMatrix(X_train_scaled, y_train)\n",
    "# dvalid = xgb.DMatrix(X_test_scaled, y_test)\n",
    "# type(dtrain)\n",
    "\n",
    "\n",
    "# # XGBoost Parameters 2\n",
    "# params = {}\n",
    "# params['objective'] = 'binary:logistic'\n",
    "# #params['objective'] = 'multi:softmax'\n",
    "# #params['objective'] = 'reg:linear'\n",
    "# params['eta'] = 0.039\n",
    "# params['silent'] = True\n",
    "# params['max_depth'] = 2\n",
    "# params['subsample'] = 0.8\n",
    "# params['colsample_bytree'] = 0.9\n",
    "# params['eval_metric'] = 'auc'\n",
    "# params['random_state'] = RANDOM_STATE\n",
    "\n",
    "# watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.train(params,\n",
    "                   dtrain,\n",
    "                   MAX_ROUNDS,\n",
    "                   watchlist,\n",
    "                   early_stopping_rounds = EARLY_STOP,\n",
    "                   maximize = True,\n",
    "                   verbose_eval = VERBOSE_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_clf.predict(dvalid)\n",
    "print('XGBoost - roc_auc_score: ', roc_auc_score(y_test, preds)) \n",
    "\n",
    "# XGBoost - roc_auc_score:  0.9207827685624094\n",
    "# XGBoost - roc_auc_score:  0.9128279684449344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(preds)\n",
    "# preds = pd.DataFrame(preds, columns=['y_Predicted'])\n",
    "# y_test = pd.DataFrame(y_test, columns=['y_Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test['y_Actual'], preds['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for best XGB\n",
    "cm = pd.crosstab(y_test, preds, rownames = ['Actual'], colnames = ['Predicted'])\n",
    "fig, (ax1) = plt.subplots(ncols = 1, figsize = (5, 5))\n",
    "sns.heatmap(cm, xticklabels = ['y_0', 'y_1'], yticklabels = ['y_0', 'y_1'], \n",
    "            annot = True, ax = ax1,\n",
    "            linewidths = .2, linecolor = 'Darkblue', cmap ='Blues')\n",
    "plt.title('confusion Matrix', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy_xgb = mt.accuracy_score(y_test, preds)\n",
    "total_precision_xgb = precision_score(y_test, preds)\n",
    "classification_rpt_xgb = classification_report(y_test, preds)\n",
    "print (\"XGB accuracy with corresponding parameter settings\")\n",
    "print('XGB classifier accuracy with optimal parameters is: %.3f'%(total_accuracy_xgb))\n",
    "print('XGB classifier precision with optimal parameters is: %.3f'%(total_precision_xgb))\n",
    "print('XGB classifier classsification report with optimal parameters is: \\n',(classification_rpt_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "#at least include the parameters already included in the baseline model for chance to find one better than base model.\n",
    "params = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.9],\n",
    "        'max_depth': [2, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "folds = 3\n",
    "param_comb = 3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "#random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "xgb_algo = xgb.XGBClassifier()\n",
    "random_search = RandomizedSearchCV(xgb_algo,\n",
    "                                   param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train_scaled,y_train), verbose=50, random_state=2000)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9013276226602549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = timer(None)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.6, gamma=2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints=None,\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing= None, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "              reg_lambda=1, scale_pos_weight=1, subsample=0.6, tree_method=None,\n",
    "              validate_parameters=False, verbosity=None)\n",
    "\n",
    "xgb_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer the testing time\n",
    "start_time = timer(None)\n",
    "preds = xgb_best.predict(X_test_scaled)\n",
    "timer(start_time)\n",
    "print('XGB - roc_auc_score: ', roc_auc_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter searching did not improve the roc auc because used very limited parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cost\n",
    "\n",
    "# cost function:\n",
    "#  Total Cost = 10 * Count of FP + 500 * Count of FN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
