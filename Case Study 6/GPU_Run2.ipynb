{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to Ensure GPU Functional and Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from  IPython import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "print(tf.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ Check to see if CUDA GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=True, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ Try new function based on warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ I was wondering how to make sure GPU does the processing rather than CPU. I found the following excerpt from Tensorflow documentation:  \n",
    "\n",
    "\"If a TensorFlow operation has both CPU and GPU implementations, by default the GPU devices will be given priority when the operation is assigned to a device. For example, tf.matmul has both CPU and GPU kernels. On a system with devices CPU:0 and GPU:0, the GPU:0 device will be selected to run tf.matmul unless you explicitly request running it on another device.\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "#os.chdir('C:\\\\Users\\\\danie\\\\Documents\\\\GitHub\\\\Quantifying-The-World\\\\Case Study 6\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ To get the tensorflow docs packages working I had to clone the github repository to my local file system and run:  \n",
    "_pip install -q C:\\Users\\danie\\Documents\\GitHub\\docs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "gz = tf.keras.utils.get_file('HIGGS.csv.gz', 'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz')\n",
    "FEATURES = 28\n",
    "ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")\n",
    "\n",
    "def pack_row(*row):\n",
    "  label = row[0]\n",
    "  features = tf.stack(row[1:],1)\n",
    "  return features, label\n",
    "\n",
    "packed_ds = ds.batch(10000).map(pack_row).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,label in packed_ds.batch(1000).take(1):\n",
    "  print(features[0])\n",
    "  plt.hist(features.numpy().flatten(), bins = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DD:__ This is where we will tweek to mimic the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5 million train and 100000 validation as per article\n",
    "#Batch suze = 1000 per article's Github\n",
    "\n",
    "N_VALIDATION = int(100000)\n",
    "N_TRAIN = int(2500000)\n",
    "BUFFER_SIZE = int(2500000)\n",
    "BATCH_SIZE = 1000\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ds = packed_ds.take(N_VALIDATION).cache()\n",
    "train_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()\n",
    "validate_ds = validate_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reproduced_model = tf.keras.Sequential([\n",
    "    layers.Dense(300, activation='tanh',\n",
    "                 kernel_regularizer=regularizers.l2(0.00001),\n",
    "                 input_shape=(FEATURES,)),\n",
    "    layers.Dense(300, activation='tanh'),\n",
    "    layers.Dropout(0.5),\n",
    "#    layers.Dense(300, activation='tanh'),\n",
    "#    layers.Dense(300, activation='tanh'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "reproduced_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproduced_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.05), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.losses.BinaryCrossentropy(from_logits=True,name='binary_crossentropy'),\n",
    "                  'accuracy'], run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime('%H:%M%p %Z on %b %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='binary_crossentropy', patience=10)\n",
    "\n",
    "reproduced_model.fit(train_ds,\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    epochs=10000,\n",
    "    callbacks=[callback],\n",
    "    validation_data=validate_ds,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime('%H:%M%p %Z on %b %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproduced_model.evaluate(validate_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
